 Analysis of Domain Specialization and Fusion Neurons in LLMs
본 연구는 대규모 언어 모델(LLM)이 의료(Medical)와 법률(Legal)이라는 서로 다른 전문 지식을 내부적으로 어떻게 분리하여 저장하는지, 그리고 그 접점인 의료법(Medical-Law Fusion) 지식을 처리할 때 기존 뉴런을 재사용하는지 혹은 전용 뉴런을 생성하는지 분석합니다.

-핵심 요약
모델 크기와 지식 처리: 소형 모델(1.7B)은 융합 지식을 위해 기존 뉴런을 공유(80% 이상 중복)하지만, 대형 모델(14B)은 융합 도메인 전용 독자 노드(Fusion Neurons)를 할당합니다.

뉴런의 순도(Purity): 특정 도메인에서만 압도적으로 활성화되는 전문 노드들을 발견하였으며, 이를 통해 모델 내부의 '지식 영토'를 시각화했습니다.

인과적 관계 증명: 특정 융합 노드(#6842)를 억제(Ablation)했을 때, 전문적인 법률 용어 인출 능력이 즉각적으로 상실됨을 확인했습니다.

-실험 환경 및 방법론
1. 데이터셋 구성
Source: LLM 기반 합성 데이터 

Size: 도메인별 50문장 (총 150문장)

Pre-processing: 법률 문서 특유의 숫자 편향 제거, 문장 길이(40~80자) 정규화.

2. 기술적 설정

Target Model: Qwen/Qwen2.5-14B, Qwen/Qwen2.5-1.7B

Analysis Point: 레이어별 MLP SwiGLU 출력 (h)

Pooling: 특정 전문 토큰에 대한 반응성을 포착하기 위해 문장 내 Max-pooling (Peak Activation) 강도 추출.

📊 주요 실험 결과
[실험 1] 모델 파라미터에 따른 도메인 분화 양상

Qwen-1.7B: 모든 레이어에서 의료법 노드의 대부분이 의료/법률 노드와 겹침. (지식의 압축적 저장)

Qwen-14B: Layer 12, 18, 24 구간에서 독자적인 의료법 전용 노드(최대 36개) 출현. 모델이 커질수록 융합 도메인에 대한 **전문화(Specialization)**가 일어남을 증명.

[실험 2] 도메인 전용 노드 분석 (Layer 24)

각 도메인에서 높은 순도(Purity)와 강도(Strength)를 보이는 노드와 그 반응 토큰을 추적했습니다.

도메인	노드 ID	순도	핵심 토큰	문맥 예시
MEDICAL	#2306	0.93	혈관	심혈관계 질환은 혈관 내벽에...
LEGAL	#4732	0.91	법	법령의 해석은 문구의 의미와...
FUSION	#6842	0.85	계	...통계 연구 목적으로 비식별화...
[실험 3] 노드 억제(Ablation)를 통한 인과성 검증

의료법 전문 노드 #6842를 비활성화(0으로 설정)한 후 문장 생성 변화 관찰.

Normal: "개인정보보호법에 따라 개인의 개인정보를 수집..." (전문 용어 유지)

Ablated: "개인정보보호법에 따라 개인의 정보를 수집..." (일반 용어로 퇴화)

결론: 특정 노드가 융합 도메인의 전문성을 유지하는 핵심 기전임을 입증.

-프로젝트 구조
data/: 도메인별 텍스트 데이터 (.txt)

analysis_topk.py: SwiGLU 출력 Hook, top-k 노드 벤다이어그램 

a.py: 각 도메인에 대하여 순도와 강도 출력, 반응 토큰 추적

results/: 레이어별 벤다이어그램 및 시각화 자료

- 결론 및 시사점
본 연구는 LLM이 거대해질수록 단순히 지식을 많이 암기하는 것이 아니라, 지식 간의 관계를 파악하여 융합 도메인을 위한 전용 공간을 할당한다는 것을 정량적으로 보여줍니다. 이는 특수 목적(의료법, 특허법 등) 모델 튜닝 시 어떤 뉴런을 집중적으로 관리해야 하는지에 대한 가이드라인을 제공합니다.
